{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1947264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca630d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = (320, 320)  \n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "DATA_PATH = \"../MURA-v1.1\"\n",
    "TRAIN_PATH = DATA_PATH + \"/train_labeled_studies.csv\"\n",
    "VALID_PATH = DATA_PATH + \"/valid_labeled_studies.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e684e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path, names=['Path', 'Label'], header=None)\n",
    "    image_paths, labels = [], []\n",
    "    base_dir = \"../\"  # Root dataset directory\n",
    "    for _, row in df.iterrows():\n",
    "        study_path = os.path.join(base_dir, row[\"Path\"])\n",
    "        label = row[\"Label\"]\n",
    "        for image_file in os.listdir(study_path):\n",
    "            image_path = os.path.join(study_path, image_file)\n",
    "            if image_path.endswith(\".png\") and not image_file.startswith(\"._\"):\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(label)\n",
    "    return np.array(image_paths), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c075965",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths, train_labels = load_data(TRAIN_PATH)\n",
    "valid_image_paths, valid_labels = load_data(VALID_PATH)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_image_paths, train_labels, test_size=0.1, stratify=train_labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef6984ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.40406976744186046, 1: 0.5959302325581395}\n"
     ]
    }
   ],
   "source": [
    "# Convert labels into a Pandas Series\n",
    "todf = pd.Series(train_labels)\n",
    "\n",
    "# Count occurrences of each class\n",
    "class_counts = todf.value_counts().to_dict()\n",
    "\n",
    "# Get the counts (handle cases where labels might be missing)\n",
    "NormalCount = class_counts.get(0, 0)  # Normal (0)\n",
    "AbnormalCount = class_counts.get(1, 0)  # Abnormal (1)\n",
    "\n",
    "# Compute class weights\n",
    "w1 = NormalCount / (NormalCount + AbnormalCount)  # Weight for class 0\n",
    "w2 = AbnormalCount / (NormalCount + AbnormalCount)  # Weight for class 1\n",
    "\n",
    "class_weights = {0: w2, 1: w1}  # More weight to minority class\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23cc09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "229fcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MURADataGenerator(Sequence):\n",
    "    def __init__(self, image_paths, labels, class_weights, batch_size=BATCH_SIZE, img_size=IMG_SIZE, augment=False, shuffle=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.class_weights = class_weights  # Store class weights\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.datagen = train_datagen if augment else None\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        # Generate images and labels\n",
    "        X, y = self.__data_generation(batch_paths, batch_labels)\n",
    "        \n",
    "        # Generate sample weights based on labels\n",
    "        sample_weights = np.array([self.class_weights[label] for label in batch_labels])\n",
    "        \n",
    "        return X, y, sample_weights  # Now returning (X, y, sample_weights)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.image_paths, self.labels))\n",
    "            np.random.shuffle(temp)\n",
    "            self.image_paths, self.labels = zip(*temp)\n",
    "    \n",
    "    def __data_generation(self, batch_paths, batch_labels):\n",
    "        images = []\n",
    "        for path in batch_paths:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, self.img_size)\n",
    "            img = img / 255.0  # Normalize\n",
    "            img = np.stack([img] * 3, axis=-1)  # Convert to 3 channels\n",
    "            if self.augment:\n",
    "                img = self.datagen.random_transform(img)\n",
    "            images.append(img)\n",
    "        return np.array(images).reshape(-1, *self.img_size, 3), np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8ec8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "train_generator = MURADataGenerator(X_train, y_train,class_weights, augment=True)\n",
    "valid_generator = MURADataGenerator(valid_image_paths, valid_labels,class_weights, augment=False, shuffle=False)\n",
    "test_generator = MURADataGenerator(X_test, y_test,class_weights, augment=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7966255",
   "metadata": {},
   "source": [
    "## image level performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a052aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test(pred,y_test):# Ensure predictions are flattened\n",
    "    predictions = pred.flatten()\n",
    "    predictions = (predictions > 0.5).astype(int)\n",
    "    # Convert to NumPy arrays\n",
    "    y_test = np.array(y_test).astype(int)\n",
    "    predictions = np.array(predictions).astype(int)\n",
    "\n",
    "    # Count correct and incorrect predictions\n",
    "    true_positives = np.sum((predictions == 1) & (y_test == 1))\n",
    "    true_negatives = np.sum((predictions == 0) & (y_test == 0))\n",
    "    false_positives = np.sum((predictions == 1) & (y_test == 0))\n",
    "    false_negatives = np.sum((predictions == 0) & (y_test == 1))\n",
    "\n",
    "    # Print results\n",
    "    print(f\"True Positives: {true_positives}\")\n",
    "    print(f\"True Negatives: {true_negatives}\")\n",
    "    print(f\"False Positives: {false_positives}\")\n",
    "    print(f\"False Negatives: {false_negatives}\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (true_positives + true_negatives) / len(y_test)\n",
    "    print(f\"Calculated Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"F1-Score: {f1_score:.2f}\")\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "    # Compute Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(y_test, predictions)\n",
    "    print(f\"Cohen's Kappa: {kappa:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7915ef8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86a8a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m461/461\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 76ms/step\n",
      "True Positives: 1122\n",
      "True Negatives: 1841\n",
      "False Positives: 353\n",
      "False Negatives: 365\n",
      "Calculated Accuracy: 80.49%\n",
      "Precision: 0.76\n",
      "Recall: 0.75\n",
      "F1-Score: 0.76\n",
      "Cohen's Kappa: 0.59\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"model_epoch09_val_loss0.2801.h5\")\n",
    "pred1=model.predict(test_generator)\n",
    "test(pred1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff891f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m461/461\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 92ms/step\n",
      "True Positives: 1021\n",
      "True Negatives: 1990\n",
      "False Positives: 204\n",
      "False Negatives: 466\n",
      "Calculated Accuracy: 81.80%\n",
      "Precision: 0.83\n",
      "Recall: 0.69\n",
      "F1-Score: 0.75\n",
      "Cohen's Kappa: 0.61\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"resnet101_model_epoch19_val_loss0.2636.h5\")\n",
    "pred2=model.predict(test_generator)\n",
    "test(pred2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7d4ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6297519]\n",
      "[0.88547075]\n",
      "[0.75761133]\n",
      "1\n",
      "True Positives: 1101\n",
      "True Negatives: 1937\n",
      "False Positives: 257\n",
      "False Negatives: 386\n",
      "Calculated Accuracy: 82.53%\n",
      "Precision: 0.81\n",
      "Recall: 0.74\n",
      "F1-Score: 0.77\n",
      "Cohen's Kappa: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean prediction\n",
    "ensemble_pred = (pred1 + pred2) / 2\n",
    "c=555\n",
    "print(pred1[c])\n",
    "print(pred2[c])\n",
    "print(ensemble_pred[c])\n",
    "print(y_test[c])\n",
    "\n",
    "# Evaluate the ensemble predictions\n",
    "test(ensemble_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506bb6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
